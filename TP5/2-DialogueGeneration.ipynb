{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP5 (2) - Dialogue Systems\n",
    "\n",
    "Group members:\n",
    "- Thanh Gia Hieu KHUONG\n",
    "- Ragi BHATT\n",
    "- Benedictus Kent RACHMAT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iVXycoM-vzC0",
    "outputId": "bde35f8e-ad8f-439d-eaaa-1d15b25b3f5c"
   },
   "outputs": [],
   "source": [
    "!pip install -q datasets pandas matplotlib scikit-learn transformers rouge evaluate tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "4gMctwE0v12A"
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import trange, tqdm # The progress bar\n",
    "\n",
    "import torch # DeepLearning Framework\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM # Model repository\n",
    "from datasets import load_dataset # Dataset Repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation for task oriented chatbot\n",
    "\n",
    "<img src=\"media/dialogue_patient.png\" style=\"width: 400px;\"/></div>\n",
    "\n",
    "The objective of this small project is to devellop a small chatbot using information of the corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Getting started : Try a naive generative model\n",
    "<div style={width:10%}> In this first part we will try a naive model and \"play\" with this model. The model is a simple transformer (based on gpt2 model), it's objective given a user query to answer it in natural language.</div><div><img src=\"media/transformer-block.png\" alt=\"transformer architecture\" style=\"width: 400px;\"/></div>\n",
    "\n",
    "\n",
    "**Let's start to load the model :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.06034207344055176,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "config.json",
       "rate": null,
       "total": 1021,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee7012020b8e4a57a67e0db508bb1738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.02k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.030820131301879883,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "model.safetensors",
       "rate": null,
       "total": 327657928,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c9bb6d8e20a436281c893e0c45b590f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/328M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"ThomasGerald/wozchitchat\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ThomasGerald/wozchitchat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can generate from an input text with the model (try your own input) : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATED_TEXT : I would be nice. The restaurant should serve fusion food.[BOT]I'm sorry, but there are no fusion attractions at all. Will you be still contacting the TownInfo Centre?<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "text = \"I would\" # input text\n",
    "tokenized_text = tokenizer(text, return_tensors='pt') # we tokenize the text\n",
    "generated_token_ids = model.generate(**tokenized_text, do_sample=True,\n",
    "                                     max_length=200, pad_token_id=model.config.eos_token_id) # we generate the text (sampled)\n",
    "print(f'GENERATED_TEXT : {tokenizer.decode(generated_token_ids[0])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the model as been `Adapted` using the following format :\n",
    "\n",
    "**[USER] {user_input} [BOT] {answer_of_the_system}**\n",
    "\n",
    "The model was trained to generate **{answer_of_the_system}**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.1 : Create a interactive interface following the previous format\n",
    "\n",
    "Modify the following class to make an interactive chatbot using the previous model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InteractiveChat(object):\n",
    "    def __init__(self, model, tokenizer):\n",
    "        raise NotImplementedError(\"\")\n",
    "\n",
    "    def answer(self, current_input):\n",
    "        ''' return the answer of the chatbot\n",
    "        '''\n",
    "        raise NotImplementedError(\"\")\n",
    "\n",
    "    def start(self):\n",
    "        current_answer = \"Start dialogue\"\n",
    "        current_input = \"\"\n",
    "        while(current_input != 'exit'):\n",
    "            current_input = input(\"Bot: \"+current_answer + \" \\nUser: \")\n",
    "            current_answer = self.answer(current_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ichat = InteractiveChat(model, tokenizer)\n",
    "ichat.start() # type exit if you want to stop the conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should obtain a dialogue as following (not exactly the same)\n",
    "```\n",
    "User:  I'm looking for an hotel in center of cambridge for tonight\n",
    "Bot: Might I suggest the the University Arms Hotel, is rated 4 stars and has an excellent reputation and is rated 3 stars. \n",
    "User:  How much is it?\n",
    "Bot: The price range isn't listed. Is there another type of cuisine you might like?\n",
    "```\n",
    "However all answer are not relevant !!! \n",
    "\n",
    "**Let consider in the following evaluating the model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II.The MULTIWoZ corpus\n",
    "\n",
    "The Multi-domain Wizard-of-Oz (MultiWOZ) dataset is a large-scale human-human conversational corpus spanning over seven domains, containing 8438 multi-turn dialogues, with each dialogue averaging 14 turns. Different from existing standard datasets like WOZ and DSTC2, which contain less than 10 slots and only a few hundred values, MultiWOZ has 30 (domain, slot) pairs and over 4,500 possible values. The dialogues span seven domains: restaurant, hotel, attraction, taxi, train, hospital and police. \n",
    "\n",
    "### Objective \n",
    "* Looking at the data ([lik-here](https://github.com/budzianowski/multiwoz) for original repository)\n",
    "* Evaluate the generative model\n",
    "* Discuss what are missing for a complete chatbot\n",
    "* Improving the generation : notice for this last part you are free to use any model you can run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# woz_dataset\n",
    "woz_dataset = load_dataset(\"multi_woz_v22\", trust_remote_code=True)\n",
    "training_set = woz_dataset['train']\n",
    "validation_set = woz_dataset['validation']\n",
    "test_set = woz_dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dialogue_id': 'MUL0484.json',\n",
       " 'services': ['attraction', 'train'],\n",
       " 'turns': {'turn_id': ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'],\n",
       "  'speaker': [0, 1, 0, 1, 0, 1, 0, 1, 0, 1],\n",
       "  'utterance': ['I need train reservations from norwich to cambridge',\n",
       "   'I have 133 trains matching your request. Is there a specific day and time you would like to travel?',\n",
       "   \"I'd like to leave on Monday and arrive by 18:00.\",\n",
       "   'There are 12 trains for the day and time you request. Would you like to book it now?',\n",
       "   'Before booking, I would also like to know the travel time, price, and departure time please.',\n",
       "   'There are 12 trains meeting your needs with the first leaving at 05:16 and the last one leaving at 16:16. Do you want to book one of these?',\n",
       "   'No hold off on booking for now. Can you help me find an attraction called cineworld cinema?',\n",
       "   'Yes it is a cinema located in the south part of town what information would you like on it?',\n",
       "   'Yes, that was all I needed. Thank you very much!',\n",
       "   'Thank you for using our system.'],\n",
       "  'frames': [{'service': ['train'],\n",
       "    'state': [{'active_intent': 'find_train',\n",
       "      'requested_slots': [],\n",
       "      'slots_values': {'slots_values_name': ['train-departure',\n",
       "        'train-destination'],\n",
       "       'slots_values_list': [['norwich'], ['cambridge']]}}],\n",
       "    'slots': [{'slot': [],\n",
       "      'value': [],\n",
       "      'start': [],\n",
       "      'exclusive_end': [],\n",
       "      'copy_from': [],\n",
       "      'copy_from_value': []}]},\n",
       "   {'service': [], 'state': [], 'slots': []},\n",
       "   {'service': ['train'],\n",
       "    'state': [{'active_intent': 'find_train',\n",
       "      'requested_slots': [],\n",
       "      'slots_values': {'slots_values_name': ['train-arriveby',\n",
       "        'train-day',\n",
       "        'train-departure',\n",
       "        'train-destination'],\n",
       "       'slots_values_list': [['18:00'],\n",
       "        ['monday'],\n",
       "        ['norwich'],\n",
       "        ['cambridge']]}}],\n",
       "    'slots': [{'slot': ['train-arriveby'],\n",
       "      'value': ['18:00'],\n",
       "      'start': [42],\n",
       "      'exclusive_end': [47],\n",
       "      'copy_from': [''],\n",
       "      'copy_from_value': [[]]}]},\n",
       "   {'service': [], 'state': [], 'slots': []},\n",
       "   {'service': ['train'],\n",
       "    'state': [{'active_intent': 'find_train',\n",
       "      'requested_slots': ['train-leaveat', 'train-duration', 'train-price'],\n",
       "      'slots_values': {'slots_values_name': ['train-arriveby',\n",
       "        'train-day',\n",
       "        'train-departure',\n",
       "        'train-destination'],\n",
       "       'slots_values_list': [['18:00'],\n",
       "        ['monday'],\n",
       "        ['norwich'],\n",
       "        ['cambridge']]}}],\n",
       "    'slots': [{'slot': [],\n",
       "      'value': [],\n",
       "      'start': [],\n",
       "      'exclusive_end': [],\n",
       "      'copy_from': [],\n",
       "      'copy_from_value': []}]},\n",
       "   {'service': [], 'state': [], 'slots': []},\n",
       "   {'service': ['attraction'],\n",
       "    'state': [{'active_intent': 'find_attraction',\n",
       "      'requested_slots': [],\n",
       "      'slots_values': {'slots_values_name': ['attraction-name'],\n",
       "       'slots_values_list': [['cineworld cinema']]}}],\n",
       "    'slots': [{'slot': ['attraction-name'],\n",
       "      'value': ['cineworld cinema'],\n",
       "      'start': [74],\n",
       "      'exclusive_end': [90],\n",
       "      'copy_from': [''],\n",
       "      'copy_from_value': [[]]}]},\n",
       "   {'service': [], 'state': [], 'slots': []},\n",
       "   {'service': [], 'state': [], 'slots': []},\n",
       "   {'service': [], 'state': [], 'slots': []}],\n",
       "  'dialogue_acts': [{'dialog_act': {'act_type': ['Train-Inform'],\n",
       "     'act_slots': [{'slot_name': ['departure', 'destination'],\n",
       "       'slot_value': ['norwich', 'cambridge']}]},\n",
       "    'span_info': {'act_type': ['Train-Inform', 'Train-Inform'],\n",
       "     'act_slot_name': ['departure', 'destination'],\n",
       "     'act_slot_value': ['norwich', 'cambridge'],\n",
       "     'span_start': [31, 42],\n",
       "     'span_end': [38, 51]}},\n",
       "   {'dialog_act': {'act_type': ['Train-Inform', 'Train-Request'],\n",
       "     'act_slots': [{'slot_name': ['choice'], 'slot_value': ['133']},\n",
       "      {'slot_name': ['day', 'leaveat'], 'slot_value': ['?', '?']}]},\n",
       "    'span_info': {'act_type': ['Train-Inform'],\n",
       "     'act_slot_name': ['choice'],\n",
       "     'act_slot_value': ['133'],\n",
       "     'span_start': [7],\n",
       "     'span_end': [10]}},\n",
       "   {'dialog_act': {'act_type': ['Train-Inform'],\n",
       "     'act_slots': [{'slot_name': ['arriveby', 'day'],\n",
       "       'slot_value': ['18:00', 'monday']}]},\n",
       "    'span_info': {'act_type': ['Train-Inform', 'Train-Inform'],\n",
       "     'act_slot_name': ['day', 'arriveby'],\n",
       "     'act_slot_value': ['monday', '18:00'],\n",
       "     'span_start': [21, 42],\n",
       "     'span_end': [27, 47]}},\n",
       "   {'dialog_act': {'act_type': ['Train-Inform', 'Train-OfferBook'],\n",
       "     'act_slots': [{'slot_name': ['choice'], 'slot_value': ['12']},\n",
       "      {'slot_name': ['none'], 'slot_value': ['none']}]},\n",
       "    'span_info': {'act_type': ['Train-Inform'],\n",
       "     'act_slot_name': ['choice'],\n",
       "     'act_slot_value': ['12'],\n",
       "     'span_start': [10],\n",
       "     'span_end': [12]}},\n",
       "   {'dialog_act': {'act_type': ['Train-Request'],\n",
       "     'act_slots': [{'slot_name': ['duration', 'leaveat', 'price'],\n",
       "       'slot_value': ['?', '?', '?']}]},\n",
       "    'span_info': {'act_type': [],\n",
       "     'act_slot_name': [],\n",
       "     'act_slot_value': [],\n",
       "     'span_start': [],\n",
       "     'span_end': []}},\n",
       "   {'dialog_act': {'act_type': ['Train-Inform', 'Train-OfferBook'],\n",
       "     'act_slots': [{'slot_name': ['choice', 'leaveat', 'leaveat'],\n",
       "       'slot_value': ['12', '05:16', '16:16']},\n",
       "      {'slot_name': ['none'], 'slot_value': ['none']}]},\n",
       "    'span_info': {'act_type': ['Train-Inform', 'Train-Inform', 'Train-Inform'],\n",
       "     'act_slot_name': ['choice', 'leaveat', 'leaveat'],\n",
       "     'act_slot_value': ['12', '05:16', '16:16'],\n",
       "     'span_start': [10, 65, 99],\n",
       "     'span_end': [12, 70, 104]}},\n",
       "   {'dialog_act': {'act_type': ['Attraction-Inform'],\n",
       "     'act_slots': [{'slot_name': ['name'],\n",
       "       'slot_value': ['cineworld cinema']}]},\n",
       "    'span_info': {'act_type': ['Attraction-Inform'],\n",
       "     'act_slot_name': ['name'],\n",
       "     'act_slot_value': ['cineworld cinema'],\n",
       "     'span_start': [74],\n",
       "     'span_end': [90]}},\n",
       "   {'dialog_act': {'act_type': ['Attraction-Inform', 'general-reqmore'],\n",
       "     'act_slots': [{'slot_name': ['area', 'type'],\n",
       "       'slot_value': ['south', 'cinema']},\n",
       "      {'slot_name': ['none'], 'slot_value': ['none']}]},\n",
       "    'span_info': {'act_type': ['Attraction-Inform', 'Attraction-Inform'],\n",
       "     'act_slot_name': ['type', 'area'],\n",
       "     'act_slot_value': ['cinema', 'south'],\n",
       "     'span_start': [12, 34],\n",
       "     'span_end': [18, 39]}},\n",
       "   {'dialog_act': {'act_type': ['general-thank'],\n",
       "     'act_slots': [{'slot_name': ['none'], 'slot_value': ['none']}]},\n",
       "    'span_info': {'act_type': [],\n",
       "     'act_slot_name': [],\n",
       "     'act_slot_value': [],\n",
       "     'span_start': [],\n",
       "     'span_end': []}},\n",
       "   {'dialog_act': {'act_type': ['general-bye'],\n",
       "     'act_slots': [{'slot_name': ['none'], 'slot_value': ['none']}]},\n",
       "    'span_info': {'act_type': [],\n",
       "     'act_slot_name': [],\n",
       "     'act_slot_value': [],\n",
       "     'span_start': [],\n",
       "     'span_end': []}}]}}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.1 Get all the tuple of the test set \n",
    "\n",
    "Create a Dataframe with two columns, one containing the column of the user query and the other containing the bot answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "user_query = []\n",
    "bot_answer = []\n",
    "\n",
    "raise NotImplementedError(\"\")\n",
    "\n",
    "pd.DataFrame({'user_query': user_query, 'bot_answer':bot_answer})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.2 Generate the different output for user query\n",
    "Select the 50 first lines (if you get access to gpus you can try to generate all answers) and generates from user_query a bot answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dSnXat8sv3a8",
    "outputId": "20827573-2211-4590-b96b-72eb10471648",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raise NotImplementedError(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.3 Evaluate the performance of the system\n",
    "You can now evaluate the performance of the systems on the generated sample you get. **You will try two metrics :**\n",
    "* A First approach base on common words between the ground truth and the generation\n",
    "* You are free to chose the second approach (BERTScore, ROUGE, BLEU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2XKKKfs6wUE5",
    "outputId": "37bbfd14-a4c8-4983-918c-f9ab0db743c8"
   },
   "outputs": [],
   "source": [
    "raise NotImplementedError(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise NotImplementedError(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Improving performances\n",
    "\n",
    "**It is now up to you to improve the following model !!!**\n",
    "* You are free to choose any architecture/model (even pretrained one to improve performances)\n",
    "* You can add additional information in the input of the model\n",
    "* You will find in the annex how the model has been trained !!!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANNEXE : Training/Fine-Tuning Material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "396e964b8ffe417dba352963d45e8042",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.02k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a69cc8a0d544874b64f34b34858335e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/328M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dc13ead0e0b4999a067cfa7b5c32ede",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/119 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d80dfad1ae804a0f9eda928ca8256430",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/504 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79b7a362c09143bdb7ec838f2964dad2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a79c8f2d75a74e5fbb9d0d2c4473293d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f84d68240ad47d2a9d971909d89be21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f9994fb6eef4d87bab4e6ee710193bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/245 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilgpt2\")\n",
    "tokenizer.add_special_tokens({'pad_token': '<|endoftext|>'})\n",
    "model = AutoModelForCausalLM.from_pretrained(\"distilbert/distilgpt2\")\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MFyuuKf4xcWK"
   },
   "source": [
    "## Implement the dataset module\n",
    "\n",
    "Create an object having as parent `torch.utils.data.dataset` implementing that return previous turn and answer of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "euhCckxZxNGN"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class WoZGenerationDataset:\n",
    "    def __init__(self, dataset, window_size=3):\n",
    "        self.dataset = dataset\n",
    "        self.window_size = window_size\n",
    "        self.index = []\n",
    "        for i, dial in enumerate(dataset):\n",
    "            for j, speaker in enumerate(dial['turns']['speaker']):\n",
    "                if speaker == 1:\n",
    "                    self.index.append((i,j))\n",
    "    def __len__(self):\n",
    "        return len(self.index)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        i, j = self.index[index]\n",
    "        dial = self.dataset[i]['turns']['utterance']\n",
    "\n",
    "        turns = dial[j-1] if(j!= 0) else ''\n",
    "        answer = dial[j]\n",
    "        return {'turns': turns,\n",
    "                'answer': answer}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "KBvXWOVdyoFr"
   },
   "outputs": [],
   "source": [
    "class DialogueCollator(Dataset):\n",
    "    def __init__(self, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "    def __call__(self, data):\n",
    "        input_tokens = self.tokenizer(['[USER]' + d['turns'] + \"[BOT]\" + d['answer'] for d in data],\n",
    "                                 return_tensors='pt', return_length=True, padding=True)\n",
    "        return {\n",
    "            'input_ids': input_tokens.input_ids,\n",
    "            'attention_mask': input_tokens.attention_mask\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ipmEgeiT0rAD"
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import trange, tqdm\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class Trainer():\n",
    "    def __init__(self, model, padding_idx=100):\n",
    "        self.model = model\n",
    "        self.optimizer = None\n",
    "\n",
    "    def at_training_start(self, learning_rate = 1e-3):\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)\n",
    "        self.criterion = nn.CrossEntropyLoss(ignore_index=50257)\n",
    "\n",
    "    def validation_step(self, data):\n",
    "        pass\n",
    "\n",
    "    def training_step(self, data):\n",
    "        y_pred = self.model(**data)\n",
    "        y_truth = data[\"input_ids\"][:, 1:].flatten()\n",
    "\n",
    "        loss_reconstruction = self.criterion(y_pred.logits[:,:-1].reshape(y_truth.shape[0], -1), y_truth)\n",
    "        (loss_reconstruction).backward()\n",
    "        return loss_reconstruction.item()\n",
    "\n",
    "    def on_validation_end(self, resp):\n",
    "        pass\n",
    "\n",
    "    def validation(self, validation_dl):\n",
    "        pass\n",
    "\n",
    "    def fit(self,\n",
    "            training_dl,\n",
    "            validation_dl,\n",
    "            learning_rate = 1e-3,\n",
    "            validation_frequency = 8,\n",
    "            max_iter = 10000,\n",
    "            use_gpu=False,\n",
    "\n",
    "        ):\n",
    "        if(use_gpu):\n",
    "          self.model = self.model.cuda()\n",
    "        self.at_training_start(learning_rate)\n",
    "\n",
    "        iter_count = 0\n",
    "        loss_buffer = []\n",
    "        pbar = trange(max_iter)\n",
    "\n",
    "        while(iter_count < max_iter):\n",
    "            for data in training_dl:\n",
    "                if use_gpu:\n",
    "                    data = {k:v.cuda() for k, v in data.items()}\n",
    "                self.optimizer.zero_grad()\n",
    "                loss_buffer += [self.training_step(data)]\n",
    "                self.optimizer.step()\n",
    "\n",
    "                if(iter_count  % validation_frequency == 0):\n",
    "                    print(\"Loss at iteration %s is %s\"%(iter_count, np.mean(loss_buffer)))\n",
    "                    self.validation(validation_dl)\n",
    "                    loss_buffer = []\n",
    "                iter_count += 1\n",
    "                pbar.update(1)\n",
    "                if(iter_count >= max_iter):\n",
    "                  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ZNNjwKBmnfZk"
   },
   "outputs": [],
   "source": [
    "training_set = WoZGenerationDataset(dataset['train'])\n",
    "collator = DialogueCollator(tokenizer)\n",
    "training_dl = DataLoader(training_set, batch_size=32, shuffle=True, collate_fn=collator, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 506,
     "referenced_widgets": [
      "ad3d02f6521f4c54a92b23f1c34f4340",
      "de6ec2c4dece46e5824c27537d485771",
      "c96cb887dba54c72b44a48309982858c",
      "4adf23ada29f44b5b696cfd3933dffea",
      "ae0f4c56a3454aa8ad1373b68a72d93a",
      "144715c9b5b74737804151071fcf7c97",
      "f3bec5e14eca44fd9be26d8062eecd9e",
      "d90f3f793b5b42c3b551b1df34d471d4",
      "6c7b190f3941429cb21289e570c73d61",
      "935e276981b247248faf817c3743e30e",
      "9d83c3aafb4c4038b1c39685c8238414"
     ]
    },
    "id": "_wvY1TMAn1dh",
    "outputId": "f978d487-19fd-4d94-f119-2948e5c27bb9"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f71ce6040e884d04b7a77ce40f64d76f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at iteration 0 is 7.432340621948242\n",
      "Loss at iteration 250 is 1.271711953163147\n",
      "Loss at iteration 500 is 1.0407882208824157\n",
      "Loss at iteration 750 is 0.9919485347270965\n",
      "Loss at iteration 1000 is 0.9869995164871216\n"
     ]
    }
   ],
   "source": [
    "my_trainer = Trainer(model)\n",
    "my_trainer.fit(training_dl, None, validation_frequency=250, use_gpu=True, max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "6ymfF5TorsLW"
   },
   "outputs": [],
   "source": [
    "class Chatbot(object):\n",
    "  def __init__(self):\n",
    "    pass\n",
    "\n",
    "  def answer(self, current_input):\n",
    "    return \"Not Implemented\"\n",
    "\n",
    "  def start(self):\n",
    "    current_answer = \"Start dialogue\"\n",
    "    current_input = \"\"\n",
    "    while(current_input != 'exit'):\n",
    "      current_input = input(\"Bot: \"+current_answer + \" \\nUser: \")\n",
    "      current_answer = self.answer(current_input)\n",
    "\n",
    "class ChitChat(Chatbot):\n",
    "  def __init__(self, model, tokenizer, collator, history_len = 1):\n",
    "    self.model = model\n",
    "    self.tokenizer = tokenizer\n",
    "    self.utterance = []\n",
    "    self.hlen = history_len\n",
    "\n",
    "  def answer(self, current_input):\n",
    "    self.utterance.append('[USER]'+current_input)\n",
    "    tokenized_text = self.tokenizer(''.join(self.utterance[max(0, len(self.utterance) - self.hlen): ]), return_tensors='pt')\n",
    "    generated_token_ids = self.model.generate(**tokenized_text, do_sample=True, max_length=200, pad_token_id=model.config.eos_token_id)[0]\n",
    "    answer = self.tokenizer.decode(generated_token_ids).split('[BOT]')[-1][:-len('<|endoftext|>')]\n",
    "    self.utterance.append('[BOT]'+answer)\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "Xkv9SHaxxoiJ"
   },
   "outputs": [],
   "source": [
    "cb = ChitChat(model.cpu(), tokenizer, collator, history_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "MduRYjM0x0Bk"
   },
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"ThomasGerald/wozchitchat\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ThomasGerald/wozchitchat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChitChat(Chatbot):\n",
    "  def __init__(self, model, tokenizer, history_len = 1):\n",
    "    self.model = model\n",
    "    self.tokenizer = tokenizer\n",
    "    self.utterance = []\n",
    "    self.hlen = history_len\n",
    "\n",
    "  def answer(self, current_input):\n",
    "    self.utterance.append('[USER]'+current_input)\n",
    "    tokenized_text = self.tokenizer(''.join(self.utterance[max(0, len(self.utterance) - self.hlen): ]), return_tensors='pt')\n",
    "    generated_token_ids = self.model.generate(**tokenized_text, do_sample=True, max_length=200, pad_token_id=model.config.eos_token_id)[0]\n",
    "    answer = self.tokenizer.decode(generated_token_ids).split('[BOT]')[-1][:-len('<|endoftext|>')].split('[USER]')[0]\n",
    "    self.utterance.append('[BOT]'+answer)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb = ChitChat(model.cpu(), tokenizer, history_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Start dialogue \n",
      "User:  I'm looking for an hotel in center of cambridge for tonight\n",
      "Bot: Might I suggest the the University Arms Hotel, is rated 4 stars and has an excellent reputation and is rated 3 stars. \n",
      "User:  How much is it?\n",
      "Bot: The price range isn't listed. Is there another type of cuisine you might like? \n",
      "User:  exit\n"
     ]
    }
   ],
   "source": [
    "cb.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMcm7ZIf8SKsTTPhRyWk3Ln",
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "144715c9b5b74737804151071fcf7c97": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4adf23ada29f44b5b696cfd3933dffea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_935e276981b247248faf817c3743e30e",
      "placeholder": "​",
      "style": "IPY_MODEL_9d83c3aafb4c4038b1c39685c8238414",
      "value": " 1053/2000 [13:55&lt;13:21,  1.18it/s]"
     }
    },
    "6c7b190f3941429cb21289e570c73d61": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "935e276981b247248faf817c3743e30e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9d83c3aafb4c4038b1c39685c8238414": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ad3d02f6521f4c54a92b23f1c34f4340": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_de6ec2c4dece46e5824c27537d485771",
       "IPY_MODEL_c96cb887dba54c72b44a48309982858c",
       "IPY_MODEL_4adf23ada29f44b5b696cfd3933dffea"
      ],
      "layout": "IPY_MODEL_ae0f4c56a3454aa8ad1373b68a72d93a"
     }
    },
    "ae0f4c56a3454aa8ad1373b68a72d93a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c96cb887dba54c72b44a48309982858c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d90f3f793b5b42c3b551b1df34d471d4",
      "max": 2000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6c7b190f3941429cb21289e570c73d61",
      "value": 1053
     }
    },
    "d90f3f793b5b42c3b551b1df34d471d4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de6ec2c4dece46e5824c27537d485771": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_144715c9b5b74737804151071fcf7c97",
      "placeholder": "​",
      "style": "IPY_MODEL_f3bec5e14eca44fd9be26d8062eecd9e",
      "value": " 53%"
     }
    },
    "f3bec5e14eca44fd9be26d8062eecd9e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
