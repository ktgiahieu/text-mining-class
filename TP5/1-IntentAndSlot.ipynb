{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP5 (1) - Dialogue Systems\n",
    "\n",
    "Group members:\n",
    "- Thanh Gia Hieu KHUONG\n",
    "- Ragi BHATT\n",
    "- Benedictus Kent RACHMAT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q datasets pandas matplotlib scikit-learn transformers rouge evaluate tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unzip:  cannot find or open 1-IntentAndSlot.zip, 1-IntentAndSlot.zip.zip or 1-IntentAndSlot.zip.ZIP.\n"
     ]
    }
   ],
   "source": [
    "!wget https://gitlab.dsi.universite-paris-saclay.fr/thomas.gerald/textminingandchatbot/-/raw/main/tp/TP-1/tp-content.zip?ref_type=heads&inline=false\n",
    "!unzip tp-content.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JOINT INTENT DETECTION AND SLOT FILLING\n",
    "\n",
    "In this application we will develop different NLU systems on the ATIS, SNIPS and MEDIA datasets. The ATIS corpus a flight reservation dialogue dataset, the data are provided in the BIO format. The SNIPS corpus regroup different intent from reservation to playlist management. The MEDIA dataset is a french corpus on hotel booking however it is noisy (due to audio transcription)\n",
    "Two different approaches will be considered in the current application for intent detection :\n",
    "* Classifier on BOW like features\n",
    "* RNN with word embedding\n",
    "For slot filling the objectives is to implement an RNN (considering same model for intent detection and slot filling)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part 1 : The dataset\n",
    "\n",
    "Explore the different dataset, how they are annotated and what are their specificities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "atis_data_path = 'data/NLU/atis-corpus/atis.{}.csv'\n",
    "snips_data_path = 'data/NLU/snips-corpus/snips.{}.csv'\n",
    "media_data_path = 'data/NLU/media-corpus/media.{}.csv'\n",
    "\n",
    "current_data_path = snips_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = pd.read_csv(current_data_path.format('train'), index_col='id')\n",
    "validation_set = pd.read_csv(current_data_path.format('dev'), index_col='id')\n",
    "testing_set = pd.read_csv(current_data_path.format('test'), index_col='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Plotting the data\n",
    "Plot both intent and slots fot the different corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_set.value_counts('intent').plot.bar()\n",
    "plt.title('Training set')\n",
    "plt.xlabel('Intent')\n",
    "plt.ylabel('Number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raise NotImplementedError('Plot the slots')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'file': 'data/NLU/atis-corpus/atis.train.csv',\n",
       "  'number_of_intents': 17,\n",
       "  'most_frequent_intent': 'atis_flight',\n",
       "  'number_of_slots': 99,\n",
       "  'most_frequent_slot': 'O',\n",
       "  'intents_distribution': {'atis_flight': 3173,\n",
       "   'atis_airfare': 351,\n",
       "   'atis_ground_service': 207,\n",
       "   'atis_airline': 139,\n",
       "   'atis_abbreviation': 94,\n",
       "   'atis_aircraft': 70,\n",
       "   'atis_quantity': 41,\n",
       "   'atis_flight_time': 38,\n",
       "   'atis_capacity': 29,\n",
       "   'atis_distance': 24,\n",
       "   'atis_airport': 23,\n",
       "   'atis_flight#atis_airfare': 21,\n",
       "   'atis_city': 18,\n",
       "   'atis_ground_fare': 18,\n",
       "   'atis_flight_no': 16,\n",
       "   'atis_meal': 9,\n",
       "   'atis_restriction': 3},\n",
       "  'slots_distribution': {'O': 25907,\n",
       "   'B-fromloc.city_name': 3587,\n",
       "   'B-toloc.city_name': 2526,\n",
       "   'I-fromloc.city_name': 629,\n",
       "   'I-toloc.city_name': 607,\n",
       "   'B-airline_name': 562,\n",
       "   'B-depart_date.day_name': 510,\n",
       "   'B-depart_date.month_name': 331,\n",
       "   'B-depart_time.period_of_day': 306,\n",
       "   'B-round_trip': 291,\n",
       "   'B-depart_time.time_relative': 287,\n",
       "   'I-round_trip': 281,\n",
       "   'B-depart_time.time': 281,\n",
       "   'I-airline_name': 275,\n",
       "   'B-cost_relative': 268,\n",
       "   'B-flight_mod': 250,\n",
       "   'B-depart_date.day_number': 201,\n",
       "   'B-class_type': 176,\n",
       "   'B-arrive_time.time_relative': 162,\n",
       "   'B-arrive_time.time': 152,\n",
       "   'I-class_type': 132,\n",
       "   'I-depart_time.time': 123,\n",
       "   'B-flight_stop': 109,\n",
       "   'I-fromloc.airport_name': 83,\n",
       "   'B-fromloc.airport_name': 75,\n",
       "   'B-airline_code': 75,\n",
       "   'B-city_name': 72,\n",
       "   'B-stoploc.city_name': 71,\n",
       "   'B-depart_date.date_relative': 70,\n",
       "   'B-flight_number': 56,\n",
       "   'I-depart_date.day_number': 56,\n",
       "   'I-arrive_time.time': 56,\n",
       "   'B-flight_time': 50,\n",
       "   'B-or': 49,\n",
       "   'B-fromloc.state_code': 49,\n",
       "   'B-toloc.state_code': 48,\n",
       "   'B-toloc.state_name': 46,\n",
       "   'I-cost_relative': 45,\n",
       "   'B-airport_name': 44,\n",
       "   'B-depart_date.today_relative': 42,\n",
       "   'B-fromloc.state_name': 42,\n",
       "   'B-arrive_date.day_name': 40,\n",
       "   'B-arrive_date.month_name': 40,\n",
       "   'B-transport_type': 39,\n",
       "   'B-depart_time.period_mod': 39,\n",
       "   'B-connect': 35,\n",
       "   'B-fare_amount': 33,\n",
       "   'B-economy': 31,\n",
       "   'B-flight_days': 29,\n",
       "   'B-fare_basis_code': 28,\n",
       "   'I-airport_name': 27,\n",
       "   'B-toloc.airport_name': 27,\n",
       "   'I-flight_time': 24,\n",
       "   'I-stoploc.city_name': 23,\n",
       "   'B-meal': 23,\n",
       "   'I-toloc.airport_name': 23,\n",
       "   'B-mod': 23,\n",
       "   'B-meal_description': 22,\n",
       "   'I-city_name': 19,\n",
       "   'B-depart_time.end_time': 18,\n",
       "   'B-depart_time.start_time': 18,\n",
       "   'B-arrive_time.start_time': 18,\n",
       "   'I-transport_type': 17,\n",
       "   'B-arrive_time.end_time': 17,\n",
       "   'B-arrive_time.period_of_day': 16,\n",
       "   'B-aircraft_code': 15,\n",
       "   'B-fromloc.airport_code': 13,\n",
       "   'I-fare_amount': 12,\n",
       "   'B-arrive_date.day_number': 12,\n",
       "   'B-airport_code': 12,\n",
       "   'B-restriction_code': 11,\n",
       "   'I-flight_mod': 10,\n",
       "   'B-arrive_date.date_relative': 10,\n",
       "   'I-flight_stop': 9,\n",
       "   'I-depart_time.start_time': 8,\n",
       "   'I-arrive_time.start_time': 7,\n",
       "   'I-fromloc.state_name': 7,\n",
       "   'B-toloc.airport_code': 6,\n",
       "   'I-toloc.state_name': 5,\n",
       "   'B-depart_date.year': 4,\n",
       "   'B-state_name': 4,\n",
       "   'I-depart_date.today_relative': 4,\n",
       "   'I-depart_time.end_time': 4,\n",
       "   'I-restriction_code': 4,\n",
       "   'B-return_date.date_relative': 3,\n",
       "   'I-depart_time.period_of_day': 3,\n",
       "   'B-meal_code': 3,\n",
       "   'I-economy': 3,\n",
       "   'B-period_of_day': 2,\n",
       "   'B-day_name': 2,\n",
       "   'B-arrive_time.period_mod': 2,\n",
       "   'I-arrive_time.time_relative': 2,\n",
       "   'B-toloc.country_name': 2,\n",
       "   'B-state_code': 1,\n",
       "   'I-meal_code': 1,\n",
       "   'B-return_date.month_name': 1,\n",
       "   'B-stoploc.state_code': 1,\n",
       "   'I-return_date.date_relative': 1,\n",
       "   'I-arrive_time.end_time': 1}},\n",
       " {'file': 'data/NLU/media-corpus/media.train.csv',\n",
       "  'number_of_intents': 0,\n",
       "  'most_frequent_intent': None,\n",
       "  'number_of_slots': 145,\n",
       "  'most_frequent_slot': 'O',\n",
       "  'intents_distribution': {},\n",
       "  'slots_distribution': {'O': 32368,\n",
       "   'reponse-B': 5926,\n",
       "   'command-tache-I': 5105,\n",
       "   'temps-date-I': 2896,\n",
       "   'command-tache-B': 2102,\n",
       "   'nombre-chambre-B': 1761,\n",
       "   'lienRef-coRef-B': 1596,\n",
       "   'localisation-ville-B': 1491,\n",
       "   'hotel-services-I': 1489,\n",
       "   'objet-B': 1475,\n",
       "   'localisation-lieuRelatif-I': 1466,\n",
       "   'localisation-ville-I': 1458,\n",
       "   'temps-date-B': 1365,\n",
       "   'nom-hotel-I': 1351,\n",
       "   'chambre-type-I': 1293,\n",
       "   'connectProp-B': 1292,\n",
       "   'reponse-I': 1212,\n",
       "   'chambre-type-B': 1160,\n",
       "   'objetBD-B': 1110,\n",
       "   'nombre-chambre-I': 1104,\n",
       "   'objet-I': 1085,\n",
       "   'comparatif-paiement-I': 1078,\n",
       "   'paiement-montant-entier-B': 1037,\n",
       "   'paiement-monnaie-B': 1017,\n",
       "   'localisation-distanceRelative-I': 950,\n",
       "   'paiement-montant-entier-I': 885,\n",
       "   'localisation-lieuRelatif-B': 850,\n",
       "   'hotel-services-B': 798,\n",
       "   'temps-mois-I': 737,\n",
       "   'hotel-marque-I': 731,\n",
       "   'localisation-distanceRelative-B': 729,\n",
       "   'comparatif-paiement-B': 704,\n",
       "   'sejour-nbEnfant-I': 592,\n",
       "   'temps-unite-B': 575,\n",
       "   'temps-mois-B': 561,\n",
       "   'nombre-I': 551,\n",
       "   'sejour-nbCouple-I': 545,\n",
       "   'sejour-nbNuit-I': 527,\n",
       "   'command-dial-I': 523,\n",
       "   'nom-hotel-B': 516,\n",
       "   'objetBD-I': 500,\n",
       "   'hotel-marque-B': 449,\n",
       "   'sejour-nbPersonne-I': 411,\n",
       "   'chambre-equipement-I': 410,\n",
       "   'nombre-B': 369,\n",
       "   'evenement-I': 357,\n",
       "   'sejour-nbNuit-B': 343,\n",
       "   'rang-temps-I': 337,\n",
       "   'lienRef-elsEns-B': 315,\n",
       "   'temps-axeTps-B': 312,\n",
       "   'sejour-nbCouple-B': 289,\n",
       "   'nombre-temps-I': 287,\n",
       "   'sejour-nbEnfant-B': 286,\n",
       "   'hotel-parking-I': 273,\n",
       "   'command-dial-B': 268,\n",
       "   'lienRef-coDom-B': 250,\n",
       "   'nombre-temps-B': 249,\n",
       "   'nombre-hotel-B': 231,\n",
       "   'rang-temps-B': 216,\n",
       "   'chambre-equipement-B': 213,\n",
       "   'sejour-nbPersonne-B': 212,\n",
       "   'localisation-arrondissement-I': 203,\n",
       "   'connectProp-I': 173,\n",
       "   'lienRef-coDom-I': 136,\n",
       "   'temps-axeTps-I': 136,\n",
       "   'sejour-nbAdulte-I': 136,\n",
       "   'hotel-etoile-I': 131,\n",
       "   'temps-jour-mois-I': 131,\n",
       "   'evenement-B': 126,\n",
       "   'nombre-hotel-I': 117,\n",
       "   'lienRef-coRef-I': 116,\n",
       "   'rang-hotel-B': 115,\n",
       "   'hotel-parking-B': 107,\n",
       "   'temps-jourFerie-I': 103,\n",
       "   'unknown-I': 97,\n",
       "   'rang-B': 96,\n",
       "   'localisation-arrondissement-B': 90,\n",
       "   'paiement-montantQualitatif-I': 87,\n",
       "   'localisation-quartier-B': 86,\n",
       "   'nom-B': 82,\n",
       "   'temps-annee-I': 82,\n",
       "   'localisation-rue-I': 81,\n",
       "   'sejour-nbAdulte-B': 81,\n",
       "   'temps-jour-mois-B': 80,\n",
       "   'chambre-voisine-I': 71,\n",
       "   'nom-I': 70,\n",
       "   'chambre-standing-I': 69,\n",
       "   'localisation-quartier-I': 67,\n",
       "   'chambre-fumeur-I': 65,\n",
       "   'nombre-chambre-disponible-I': 63,\n",
       "   'connectAttr-B': 62,\n",
       "   'hotel-etoile-B': 58,\n",
       "   'temps-plageTps-I': 56,\n",
       "   'localisation-cardinal-I': 54,\n",
       "   'chambre-fumeur-B': 52,\n",
       "   'localisation-cardinal-B': 49,\n",
       "   'temps-plageTps-B': 49,\n",
       "   'temps-jourFerie-B': 44,\n",
       "   'unknown-B': 42,\n",
       "   'paiement-montantQualitatif-B': 42,\n",
       "   'temps-annee-B': 41,\n",
       "   'nombre-reservation-I': 40,\n",
       "   'chambre-voisine-B': 37,\n",
       "   'temps-unite-I': 37,\n",
       "   'chambre-standing-B': 37,\n",
       "   'temps-plageRelative-B': 32,\n",
       "   'localisation-rue-B': 31,\n",
       "   'rang-hotel-I': 31,\n",
       "   'nombre-chambre-disponible-B': 29,\n",
       "   'hotel-etat-complet-I': 26,\n",
       "   'temps-jour-semaine-I': 21,\n",
       "   'temps-jour-semaine-B': 20,\n",
       "   'nombre-reservation-B': 19,\n",
       "   'localisation-departement-I': 19,\n",
       "   'hotel-etat-complet-B': 18,\n",
       "   'comparatif-temps-B': 18,\n",
       "   'temps-plageRelative-I': 16,\n",
       "   'nombreNonDigit-B': 15,\n",
       "   'comparatif-temps-I': 15,\n",
       "   'lienRef-elsEns-I': 14,\n",
       "   'rang-reservation-B': 10,\n",
       "   'comparatif-B': 8,\n",
       "   'connectAttr-I': 8,\n",
       "   'personne-nomDeFamille-I': 8,\n",
       "   'localisation-departement-B': 7,\n",
       "   'comparatif-I': 7,\n",
       "   'paiement-methodeDePaiement-I': 7,\n",
       "   'nombreNonDigit-I': 6,\n",
       "   'localisation-region-I': 4,\n",
       "   'localisation-region-B': 4,\n",
       "   'temps-heure-I': 4,\n",
       "   'temps-heure-B': 4,\n",
       "   'paiement-methodeDePaiement-B': 4,\n",
       "   'personne-nomDeFamille-B': 3,\n",
       "   'rang-I': 2,\n",
       "   'nombreNonDigit-hotel-I': 2,\n",
       "   'localisation-codePostal-I': 2,\n",
       "   'rang-reservation-I': 2,\n",
       "   'nombreNonDigit-hotel-B': 1,\n",
       "   'localisation-codePostal-B': 1,\n",
       "   'localisation-pays-B': 1,\n",
       "   'localisation-pays-I': 1,\n",
       "   'nom-client-B': 1,\n",
       "   'nom-client-I': 1,\n",
       "   'hotel-etat-B': 1}},\n",
       " {'file': 'data/NLU/snips-corpus/snips.train.csv',\n",
       "  'number_of_intents': 7,\n",
       "  'most_frequent_intent': 'GetWeather',\n",
       "  'number_of_slots': 72,\n",
       "  'most_frequent_slot': 'O',\n",
       "  'intents_distribution': {'GetWeather': 1900,\n",
       "   'PlayMusic': 1900,\n",
       "   'BookRestaurant': 1873,\n",
       "   'SearchScreeningEvent': 1859,\n",
       "   'RateBook': 1856,\n",
       "   'SearchCreativeWork': 1853,\n",
       "   'AddToPlaylist': 1842},\n",
       "  'slots_distribution': {'O': 57899,\n",
       "   'I-object_name': 7391,\n",
       "   'I-playlist': 3230,\n",
       "   'B-object_type': 3022,\n",
       "   'B-object_name': 2777,\n",
       "   'I-timeRange': 2644,\n",
       "   'B-playlist': 1989,\n",
       "   'I-movie_name': 1874,\n",
       "   'B-timeRange': 1869,\n",
       "   'B-rating_value': 1857,\n",
       "   'B-artist': 1803,\n",
       "   'I-artist': 1775,\n",
       "   'B-music_item': 1585,\n",
       "   'B-city': 1303,\n",
       "   'B-restaurant_type': 1300,\n",
       "   'I-entity_name': 1177,\n",
       "   'B-spatial_relation': 1158,\n",
       "   'B-rating_unit': 1063,\n",
       "   'B-playlist_owner': 1039,\n",
       "   'B-best_rating': 999,\n",
       "   'I-object_type': 975,\n",
       "   'B-party_size_number': 966,\n",
       "   'B-state': 963,\n",
       "   'B-object_select': 940,\n",
       "   'I-party_size_description': 903,\n",
       "   'I-spatial_relation': 835,\n",
       "   'I-geographic_poi': 824,\n",
       "   'B-country': 819,\n",
       "   'B-movie_name': 771,\n",
       "   'B-service': 715,\n",
       "   'I-location_name': 705,\n",
       "   'B-movie_type': 662,\n",
       "   'B-year': 602,\n",
       "   'B-entity_name': 570,\n",
       "   'B-location_name': 563,\n",
       "   'I-restaurant_name': 560,\n",
       "   'B-sort': 521,\n",
       "   'B-condition_temperature': 454,\n",
       "   'B-object_location_type': 445,\n",
       "   'I-city': 444,\n",
       "   'B-condition_description': 430,\n",
       "   'I-track': 410,\n",
       "   'I-album': 366,\n",
       "   'I-country': 333,\n",
       "   'B-restaurant_name': 321,\n",
       "   'B-party_size_description': 302,\n",
       "   'I-object_location_type': 291,\n",
       "   'B-object_part_of_series_type': 288,\n",
       "   'B-geographic_poi': 277,\n",
       "   'B-served_dish': 256,\n",
       "   'B-current_location': 254,\n",
       "   'I-movie_type': 221,\n",
       "   'B-cuisine': 199,\n",
       "   'B-track': 196,\n",
       "   'I-state': 195,\n",
       "   'B-album': 166,\n",
       "   'I-service': 156,\n",
       "   'B-facility': 154,\n",
       "   'I-sort': 150,\n",
       "   'I-poi': 150,\n",
       "   'B-genre': 140,\n",
       "   'B-poi': 137,\n",
       "   'I-restaurant_type': 135,\n",
       "   'I-served_dish': 128,\n",
       "   'I-current_location': 116,\n",
       "   'I-genre': 52,\n",
       "   'I-music_item': 37,\n",
       "   'I-cuisine': 28,\n",
       "   'I-facility': 14,\n",
       "   'I-object_part_of_series_type': 3,\n",
       "   'I-object_select': 3,\n",
       "   'I-playlist_owner': 1}})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def analyze_dataset(file_path): \n",
    "    df = pd.read_csv(file_path)\n",
    "    intents = df['intent'].dropna().value_counts()\n",
    "    num_intents = intents.shape[0]\n",
    "    most_frequent_intent = intents.idxmax() if num_intents > 0 else None\n",
    "\n",
    "    # Preparing slots analysis\n",
    "    all_slots = ' '.join(df['slots'].dropna()).split()\n",
    "    slots_series = pd.Series(all_slots)\n",
    "    slots_count = slots_series.value_counts()\n",
    "    num_slots = slots_count.shape[0]\n",
    "    most_frequent_slot = slots_count.idxmax() if num_slots > 0 else None\n",
    "\n",
    "    return {\n",
    "        \"file\": file_path,\n",
    "        \"number_of_intents\": num_intents,\n",
    "        \"most_frequent_intent\": most_frequent_intent,\n",
    "        \"number_of_slots\": num_slots,\n",
    "        \"most_frequent_slot\": most_frequent_slot,\n",
    "        \"intents_distribution\": intents.to_dict() if intents is not None else {},\n",
    "        \"slots_distribution\": slots_count.to_dict()\n",
    "    }\n",
    "\n",
    "sample_files = {\n",
    "    'atis': atis_data_path.format('train'),\n",
    "    'media': media_data_path.format('train'),\n",
    "    'snips': snips_data_path.format('train')\n",
    "}\n",
    "\n",
    "analysis_results = {}\n",
    "for corpus, file_path in sample_files.items():\n",
    "    analysis_results[corpus] = analyze_dataset(file_path)\n",
    "\n",
    "analysis_results['atis'], analysis_results['media'], analysis_results['snips']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Datasets characteristics\n",
    "\n",
    "### ATIS Dataset\n",
    "* **How many possible intents for the dataset?**\n",
    "  - Number of Intents: 17\n",
    "\n",
    "* **How many slots?**\n",
    "  - Number of Slots: 99\n",
    "\n",
    "* **How are they distributed? What are the most frequent values?**\n",
    "  - Most Frequent Intent: `atis_flight`\n",
    "  - Most Frequent Slot: `O`\n",
    "  - Intent Distribution: The intents are varied, with `atis_flight` being the most frequent.\n",
    "  - Slot Distribution: Most slots are 'O' (Outside), followed by location-based slots like `B-fromloc.city_name`.\n",
    "\n",
    "### Media Dataset\n",
    "* **How many possible intents for the dataset?**\n",
    "  - Number of Intents: 0 (Intents data appears to be missing or not properly labeled)\n",
    "\n",
    "* **How many slots?**\n",
    "  - Number of Slots: 27\n",
    "\n",
    "* **How are they distributed? What are the most frequent values?**\n",
    "  - Most Frequent Slot: `O`\n",
    "  - Slot Distribution: Majority are 'O' (Outside), followed by command-based slots like `command-tache-B`.\n",
    "\n",
    "### SNIPS Dataset\n",
    "* **How many possible intents for the dataset?**\n",
    "  - Number of Intents: 7\n",
    "\n",
    "* **How many slots?**\n",
    "  - Number of Slots: 72\n",
    "\n",
    "* **How are they distributed? What are the most frequent values?**\n",
    "  - Most Frequent Intent: `GetWeather` and `PlayMusic`\n",
    "  - Most Frequent Slot: `O`\n",
    "  - Intent Distribution: Evenly distributed among intents such as `GetWeather`, `PlayMusic`, `BookRestaurant`.\n",
    "  - Slot Distribution: Primarily 'O' (Outside), with frequent entity names and playlist slots like `I-object_name`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 2 Learning BOW classifiers \n",
    "From the code below propose different classifier for intent (for both snips and atis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model LogisticRegression : 0.9842857142857143\n",
      "Model MultinomialNB : 0.9771428571428571\n",
      "Model SVC : 0.9857142857142858\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "LIST_MODEL = [LogisticRegression, MultinomialNB, SVC]\n",
    "\n",
    "for model in LIST_MODEL:\n",
    "    text_clf = Pipeline([\n",
    "        ('vect', CountVectorizer()),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', model()),\n",
    "    ])\n",
    "    text_clf.fit(training_set['tokens'], training_set['intent'])\n",
    "    predicted = text_clf.predict(validation_set['tokens'])\n",
    "    print(f\"Model {model.__name__} : {np.mean(predicted == validation_set['intent'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raise NotImplementedError('Other appproaches')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill the following table replacing value and named classifiers\n",
    "\n",
    "| Dataset   | Acc Logistic Regression | Acc MultinomialNB |Acc SVM |\n",
    "| -------- | ------- |------- |------- |\n",
    "| ATIS  | 0.92    |0.84    | 0.95 |\n",
    "| SNIPS | 0.984     |0.97    |  0.985 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 3 Learning RNN\n",
    "\n",
    "### 1.1 Prepare the data and tools\n",
    "The objective of the following question is to prepare the data to run with the model.\n",
    "In this example we will create different component :\n",
    "* intent_encoder (from textual intent return its id)\n",
    "* slot_encoder (from list or string separated by space of textual slot return id)\n",
    "* tokenizer (from list or string separated by space of textual slot return id)\n",
    "* BIONLUDataset a dataset like class returning all the information necessary for training\n",
    "* Dataloader that allow to create batch of the data (usefull for training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This class encode labels or list of labels given an index\n",
    "'''\n",
    "class LabelEncoder:\n",
    "    def __init__(self, index):\n",
    "        self.index = index\n",
    "        self.iindex = {v: k for k, v in index.items()}\n",
    "    \n",
    "    def get_id_list_from_text(self, text):\n",
    "        return [self.index[w] for w in text.split()]\n",
    "\n",
    "    def get_label_list_from_id(self, label_ids):\n",
    "         return [self.iindex[lid] for lid in label_ids]\n",
    "\n",
    "    def to_label_list(self, text):\n",
    "        return text.split()\n",
    "\n",
    "    # method call can be called by instance_object(parameters)\n",
    "    def __call__(self, text):\n",
    "        return self.get_id_list_from_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_label_index(labels):\n",
    "    \"\"\"Create an index (dictionary) for labels.\"\"\"\n",
    "    label_to_id = {}\n",
    "    for label in labels:\n",
    "        if label not in label_to_id:\n",
    "            label_to_id[label] = len(label_to_id)\n",
    "    return label_to_id\n",
    "\n",
    "intents = training_set['intent'].unique()\n",
    "slots = set(slot for row in training_set['slots'] for slot in row.split())\n",
    "\n",
    "intent_index = create_label_index(intents)\n",
    "slot_index = create_label_index(slots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_encoder = LabelEncoder(intent_index)\n",
    "slot_encoder = LabelEncoder(slot_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a tokenizer\n",
    "Fill the Tokenizer class to transform text tokens into token ids. From a list of words (or string of wards separated by space) return a sequence of ids (each word as a unique id)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This class should tokenize a text or a list of tokens.\n",
    "'''  \n",
    "class Tokenizer:\n",
    "\n",
    "    def __init__(self, list_text, unk_token=\"UNKNOW_WORD\"):\n",
    "        # create a vocbulary index \n",
    "        self.vocab = np.unique([word for text in list_text for word in text.split()])\n",
    "        self.vocab_index = {w: i for i, w in enumerate(self.vocab)}\n",
    "        self.vocab_index[unk_token] = len(self.vocab_index)\n",
    "        self.unk_token = unk_token\n",
    "        \n",
    "    def __call__(self, text):\n",
    "        # Tokenize the text or word sequence\n",
    "        if isinstance(text, list):\n",
    "            return [self.vocab_index.get(word, self.vocab_index[self.unk_token]) for word in text]\n",
    "        else:\n",
    "            return [self.vocab_index.get(word, self.vocab_index[self.unk_token]) for word in text.split()]\n",
    "\n",
    "    def decode(self, ids):\n",
    "        # Decode the text ids to a sentence\n",
    "        index_to_vocab = {i: w for w, i in self.vocab_index.items()}\n",
    "        return ' '.join(index_to_vocab.get(id, self.unk_token) for id in ids)\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        # get the vocabulary lenght\n",
    "        return len(self.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(\n",
    "    list(training_set['tokens']) + \n",
    "    list(validation_set['tokens']) + \n",
    "    list(testing_set['tokens'])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the dataset\n",
    "\n",
    "The dataset class below must return all needed informations for prediction, here the **text** (initial utterance), the intent label name (**i_label**), the list of slots names for the sequence (**s_label**), the text transformed into list of tokens(**x**), the id of the coresponding intent (**i_id**), the list of ids of the coresponding slots names (**s_ids**) and, the len of the squence (the number of words) (**seq_len**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BIONLUDataset():\n",
    "    def __init__(self, data, intent_index, slot_index, text_transform):\n",
    "        self.data = data\n",
    "        self.i_enc = LabelEncoder(intent_index)\n",
    "        self.s_enc = LabelEncoder(slot_index)\n",
    "        self.t_transform = text_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.data.iloc[index]\n",
    "        text = row['tokens']\n",
    "        i_label = row['intent']\n",
    "        s_label = row['slots']\n",
    "        \n",
    "        x = self.t_transform(text)\n",
    "        i_id = self.i_enc(i_label)[0]\n",
    "        s_ids = self.s_enc(s_label)\n",
    "        \n",
    "        assert(len(s_ids) == len(x))\n",
    "        \n",
    "        return {'text': text, 'i_label': i_label, 's_labels': s_label,\n",
    "                'x': x, 'i_id': i_id, 's_ids': s_ids, \"seq_len\": len(x)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create the different set :** below we create the different, for each we give the set data, the intent_index (to allow to transform intent label to its corresponding id), the slot_index (to transform slot_type to id) and the tokenizer (which simply split text by words and return the sequence of tokens/words ids)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a simple tokenizer on all words of the corpus \n",
    "\n",
    "train = BIONLUDataset(training_set, intent_index, slot_index, tokenizer)\n",
    "val = BIONLUDataset(validation_set, intent_index, slot_index, tokenizer)\n",
    "test = BIONLUDataset(testing_set, intent_index, slot_index, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The collate function:** to load the data as batch we need to return tensors to the pytorch model we will see later. Here we need as input of the model the intents ids, the slots_ids (which is a sequence of the size of text), the input given to the model (named x)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_collator(batch):\n",
    "    i_ids = []\n",
    "    seq_len = []\n",
    "    s_ids = []\n",
    "    x = []\n",
    "    mask = []\n",
    "    for item in batch:\n",
    "        i_ids.append(item['i_id'])\n",
    "        s_ids.append(torch.LongTensor(item['s_ids']))\n",
    "        seq_len.append(item['seq_len'])\n",
    "        x.append(torch.Tensor(item['x']))\n",
    "        mask.append(torch.ones(item['seq_len']))\n",
    "\n",
    "    return{\n",
    "        \"i_ids\" : torch.LongTensor(i_ids),\n",
    "        \"s_ids\" : pad_sequence(s_ids, padding_value=-1, batch_first=True),\n",
    "        \"x\" : pad_sequence(x, padding_value=0, batch_first=True),\n",
    "        \"seq_len\" : torch.LongTensor(seq_len), \n",
    "        \"mask\": pad_sequence(mask, padding_value=0, batch_first=True)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "training_dl = DataLoader(train , batch_size=16,\n",
    "                         collate_fn=rnn_collator,\n",
    "                         shuffle=True\n",
    "                        )\n",
    "validation_dl = DataLoader(val, batch_size=16,\n",
    "                         collate_fn=rnn_collator\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from library.model import IntentSlotRNN\n",
    "\n",
    "class LSTMForClassification(nn.Module):\n",
    "    def __init__(self, vocabulary_size, embedding_size=300, hidden_size=100, n_slot=101, n_intent=17):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocabulary_size, embedding_size)\n",
    "        self.rnn = IntentSlotRNN(embedding_size, hidden_size, n_intent, n_slot)\n",
    "    \n",
    "    def forward(self, input_ids, seq_len, mask=None):\n",
    "        if mask is None:\n",
    "            mask = input_ids.new_ones(input_ids.shape).float()\n",
    "        input_ids = input_ids.long()  # Convert input_ids to LongTensor\n",
    "        emb = self.embedding(input_ids)\n",
    "        return self.rnn(emb, seq_len, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import trange\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "\n",
    "class Trainer():\n",
    "    def __init__(self, model):\n",
    "        self.model = model \n",
    "        self.optimizer = None\n",
    "\n",
    "    def before_training_loop(self, learning_rate = 1e-3):\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)\n",
    "        self.criterion = nn.CrossEntropyLoss(ignore_index=-1)\n",
    "\n",
    "    def validation_step(self, data):\n",
    "        y_pred = self.model(data[\"x\"], data[\"seq_len\"], data['mask'])    \n",
    "        y_intent_truth = data[\"i_ids\"]\n",
    "        y_slot_truth = data[\"s_ids\"]\n",
    "        #print(y_slot_truth)\n",
    "        y_intent_pred = y_pred[\"y_intent\"]\n",
    "        #print(y_pred[\"y_slot\"].shape)\n",
    "        y_slot_pred = y_pred[\"y_slot\"].view(y_slot_truth.shape[0] * y_slot_truth.shape[-1], -1)\n",
    "        minus_one = (data[\"mask\"] - 1)\n",
    "        y_slot_pred *= data[\"mask\"].view(y_slot_truth.shape[0] * y_slot_truth.shape[-1], -1)\n",
    "        # y_slot_pred += minus_one.view(y_slot_truth.shape[0] * y_slot_truth.shape[-1], -1)\n",
    "        return {\n",
    "            'mask' : minus_one.view(y_slot_truth.shape[0] * y_slot_truth.shape[-1], -1),\n",
    "            'len' : len(data['x']),\n",
    "            'intent_pred': y_intent_pred,\n",
    "            'intent_truth': y_intent_truth,\n",
    "            'slot_pred': y_slot_pred,\n",
    "            'slot_truth': y_slot_truth\n",
    "        }\n",
    "\n",
    "    def training_step(self, data):\n",
    "        y_pred = self.model(data[\"x\"], data[\"seq_len\"], data['mask'])    \n",
    "        y_intent_truth = data[\"i_ids\"]\n",
    "        y_slot_truth = data[\"s_ids\"]\n",
    "        loss_intent = self.criterion(y_pred[\"y_intent\"], y_intent_truth)\n",
    "\n",
    "        y_slot_pred = y_pred[\"y_slot\"].view(y_slot_truth.shape[0] * y_slot_truth.shape[-1], -1)\n",
    "        y_slot_pred *= data[\"mask\"].view(y_slot_truth.shape[0] * y_slot_truth.shape[-1], -1)\n",
    "            \n",
    "        loss_slot = self.criterion(y_slot_pred, y_slot_truth.view(-1))\n",
    "        (loss_slot + loss_intent).backward()\n",
    "        return loss_slot.item() + loss_intent.item()\n",
    "\n",
    "    def on_validation_end(self, resp):\n",
    "        i_truth = [d[\"intent_truth\"] for d in resp]\n",
    "        s_truth = [d[\"slot_truth\"].flatten() for d in resp]\n",
    "        \n",
    "        i_pred = [d[\"intent_pred\"] for d in resp]\n",
    "        s_pred =  [d[\"slot_pred\"].argmax(-1).flatten() + d['mask'].max(-1).values.flatten() for d in resp]\n",
    "        size = sum([d['len'] for d in resp ])\n",
    "        print('Intent validation accuracy : %s'%(((torch.cat(i_pred).argmax(-1) == torch.cat(i_truth)).sum()/size).item(),))\n",
    "        print('Slot validation accuracy : %s'%(((torch.cat(s_pred) == torch.cat(s_truth)).sum()/len(torch.cat(s_truth))).item(),))\n",
    "    \n",
    "    def validation(self, validation_dl):\n",
    "        with torch.no_grad():\n",
    "            resp = []\n",
    "            for data in validation_dl:\n",
    "                resp.append(self.validation_step(data))\n",
    "        self.on_validation_end(resp)\n",
    "\n",
    "    def fit(self, \n",
    "            training_dl,\n",
    "            validation_dl,\n",
    "            learning_rate = 1e-3,\n",
    "            validation_frequency = 128,\n",
    "            max_iter = 10000,\n",
    "        ):\n",
    "\n",
    "        self.before_training_loop(learning_rate)\n",
    "        \n",
    "        iter_count = 0\n",
    "        loss_buffer = []\n",
    "        pbar = trange(max_iter)\n",
    "        \n",
    "        while(True):\n",
    "            for data in training_dl:\n",
    "                self.optimizer.zero_grad()\n",
    "                loss_buffer += [self.training_step(data)]\n",
    "                self.optimizer.step()\n",
    "\n",
    "                if(iter_count  % validation_frequency == 0):\n",
    "                    print(\"Loss at iteration %s is %s\"%(iter_count, np.mean(loss_buffer)))\n",
    "                    self.validation(validation_dl)\n",
    "\n",
    "                iter_count += 1\n",
    "                if(iter_count >= max_iter):\n",
    "                    return\n",
    "                pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.03201580047607422,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 10000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e39a1e94b2874d41bfc33e1e1bc37d8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at iteration 0 is 7.467991590499878\n",
      "Intent validation accuracy : 0.07999999821186066\n",
      "Slot validation accuracy : 0.413607120513916\n",
      "Loss at iteration 500 is 1.4202767520066641\n",
      "Intent validation accuracy : 0.9828571677207947\n",
      "Slot validation accuracy : 0.9244890213012695\n",
      "Loss at iteration 1000 is 0.9086045275659084\n",
      "Intent validation accuracy : 0.9871428608894348\n",
      "Slot validation accuracy : 0.9504163265228271\n",
      "Loss at iteration 1500 is 0.6791249965860069\n",
      "Intent validation accuracy : 0.9900000095367432\n",
      "Slot validation accuracy : 0.9614875316619873\n",
      "Loss at iteration 2000 is 0.5407011413984185\n",
      "Intent validation accuracy : 0.9871428608894348\n",
      "Slot validation accuracy : 0.9665026664733887\n",
      "Loss at iteration 2500 is 0.45038245877190564\n",
      "Intent validation accuracy : 0.9871428608894348\n",
      "Slot validation accuracy : 0.9698145389556885\n",
      "Loss at iteration 3000 is 0.3827054629197332\n",
      "Intent validation accuracy : 0.9885714054107666\n",
      "Slot validation accuracy : 0.9705715179443359\n",
      "Loss at iteration 3500 is 0.3324736868910731\n",
      "Intent validation accuracy : 0.9871428608894348\n",
      "Slot validation accuracy : 0.9701930284500122\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [77]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m LSTMForClassification(vocabulary_size)\n\u001b[1;32m      3\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(model)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_frequency\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [64]\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, training_dl, validation_dl, learning_rate, validation_frequency, max_iter)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     83\u001b[0m loss_buffer \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(data)]\n\u001b[0;32m---> 84\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(iter_count  \u001b[38;5;241m%\u001b[39m validation_frequency \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss at iteration \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m%\u001b[39m(iter_count, np\u001b[38;5;241m.\u001b[39mmean(loss_buffer)))\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/optim/optimizer.py:113\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/optim/adam.py:157\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    153\u001b[0m                 max_exp_avg_sqs\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_exp_avg_sq\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    155\u001b[0m             state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 157\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m         \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m         \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m         \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m         \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m         \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m         \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m         \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m         \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/optim/adam.py:213\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 213\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/optim/adam.py:262\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable)\u001b[0m\n\u001b[1;32m    259\u001b[0m     grad \u001b[38;5;241m=\u001b[39m grad\u001b[38;5;241m.\u001b[39madd(param, alpha\u001b[38;5;241m=\u001b[39mweight_decay)\n\u001b[1;32m    261\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[0;32m--> 262\u001b[0m \u001b[43mexp_avg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39madd_(grad, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1)\n\u001b[1;32m    263\u001b[0m exp_avg_sq\u001b[38;5;241m.\u001b[39mmul_(beta2)\u001b[38;5;241m.\u001b[39maddcmul_(grad, grad\u001b[38;5;241m.\u001b[39mconj(), value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capturable:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vocabulary_size = len(tokenizer)\n",
    "model = LSTMForClassification(vocabulary_size)\n",
    "trainer = Trainer(model)\n",
    "trainer.fit(training_dl, validation_dl, validation_frequency=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Evaluate the model on the test set using accuracy\n",
    "* Hint : see validation step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLU:\n",
    "    def __init__(self, model, intent_encoder, slot_encoder, nlp):\n",
    "        self.nlp = nlp\n",
    "        self.model = model \n",
    "        self.intent_encoder = intent_encoder\n",
    "        self.slot_encoder = slot_encoder\n",
    "    \n",
    "    def __call__(self, text):\n",
    "        input_data = self.nlp(text)\n",
    "        with torch.no_grad():\n",
    "            y = self.model(torch.LongTensor([input_data]),  [len(input_data)])\n",
    "\n",
    "        intent = self.intent_encoder.get_label_list_from_id(y['y_intent'].max(-1)[1].tolist())\n",
    "\n",
    "        slots = self.slot_encoder.get_label_list_from_id(y['y_slot'].max(-1)[1].tolist()[0])\n",
    "        return intent, list(zip(slots, text.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlu = NLU(trainer.model, intent_encoder, slot_encoder, naive_tokenizer)\n",
    "nlu(\"i'm looking for a good restauranta in chicago\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Change the model to use pretrained embeddings !\n",
    "* You can use global pretrained embeddings for SNIPS and ATIS\n",
    "* You can use pretrained last week course embeddings for MEDIA !!! \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNS/a2Yg3HaV1/6sqmOr4GR",
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "11b8dba1f8894009898f592b28bca05d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "187480090f634458a999041d31807714": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_87ecdd23e58f4b8295d249c3d8e6077e",
      "placeholder": "​",
      "style": "IPY_MODEL_11b8dba1f8894009898f592b28bca05d",
      "value": "100%"
     }
    },
    "38ce3b07782e41b3b27e54f5816d0b8d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "62f56530a42a4d2d993f70829d18c563": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "64da4ffa91de4c12870ccd829905597c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6e7fada25dd94569933bb3c14527dcb8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_38ce3b07782e41b3b27e54f5816d0b8d",
      "placeholder": "​",
      "style": "IPY_MODEL_62f56530a42a4d2d993f70829d18c563",
      "value": " 10000/10000 [02:41&lt;00:00, 94.43it/s]"
     }
    },
    "838873ce9ea94fa790a463524c18ffa5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "87ecdd23e58f4b8295d249c3d8e6077e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "945c208409a148809c60485d3826a935": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_187480090f634458a999041d31807714",
       "IPY_MODEL_966427dbfc0140109f73ee3cce25928e",
       "IPY_MODEL_6e7fada25dd94569933bb3c14527dcb8"
      ],
      "layout": "IPY_MODEL_c89204b1a50f4915bf96f4cc9280ad0e"
     }
    },
    "966427dbfc0140109f73ee3cce25928e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_838873ce9ea94fa790a463524c18ffa5",
      "max": 10000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_64da4ffa91de4c12870ccd829905597c",
      "value": 10000
     }
    },
    "c89204b1a50f4915bf96f4cc9280ad0e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
